{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a9c48141",
      "metadata": {
        "id": "a9c48141"
      },
      "source": [
        "# Assignment-1\n",
        "\n",
        "### Pooja Bandal \n",
        "##### 2022-02-06\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f44e9298",
      "metadata": {
        "id": "f44e9298"
      },
      "source": [
        "### Installing essential libraries \n",
        "\n",
        "I need to install `nltk` and `pytrec-eval-terrier` libraries again in the notebook because I used a different environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "70782e45",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70782e45",
        "outputId": "f9aff654-7cf1-4a81-ec41-7ac97760d936"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n",
            "Collecting pytrec-eval-terrier\n",
            "  Downloading pytrec_eval_terrier-0.5.2-cp37-cp37m-manylinux2010_x86_64.whl (287 kB)\n",
            "\u001b[K     |████████████████████████████████| 287 kB 3.9 MB/s \n",
            "\u001b[?25hInstalling collected packages: pytrec-eval-terrier\n",
            "Successfully installed pytrec-eval-terrier-0.5.2\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk\n",
        "!pip install \"pytrec-eval-terrier\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing modules\n",
        "\n",
        "Importing all the modules used in the project"
      ],
      "metadata": {
        "id": "524m5nOtFzrf"
      },
      "id": "524m5nOtFzrf"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "f925d1fd",
      "metadata": {
        "id": "f925d1fd"
      },
      "outputs": [],
      "source": [
        "import concurrent.futures\n",
        "import json\n",
        "import nltk\n",
        "import os\n",
        "import pytrec_eval\n",
        "import time\n",
        "import tqdm\n",
        "\n",
        "from utils.common_utils import return_top_1_5_10_words, return_success_at_k, find_closes_match\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e4b0d90",
      "metadata": {
        "id": "7e4b0d90"
      },
      "source": [
        "#### Downloading the wordnet corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "45375ed3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45375ed3",
        "outputId": "3ca14987-6b8b-4d4b-ed18-4e50a4c14fe3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/omw-1.4.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0103389",
      "metadata": {
        "id": "f0103389"
      },
      "source": [
        "####  create a lists to store correct and incorrect spellings of words from missp.dat file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "84617d66",
      "metadata": {
        "id": "84617d66"
      },
      "outputs": [],
      "source": [
        "correct_spellings = []\n",
        "incorrect_spellings = []\n",
        "file_ = open('Data/missp.dat', 'r')\n",
        "Lines = file_.readlines()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47308a28",
      "metadata": {
        "id": "47308a28"
      },
      "source": [
        "#### Strips the newline character"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ec1b7543",
      "metadata": {
        "id": "ec1b7543"
      },
      "outputs": [],
      "source": [
        "crr_spell = ''\n",
        "icrr_spell = ''\n",
        "for line in Lines:\n",
        "    if '$' in line:\n",
        "        crr_spell = line.replace('$', '').replace('\\n', '').lower()\n",
        "    else:\n",
        "        incrr_spell = line.lower().replace('\\n', '')\n",
        "        correct_spellings.append(crr_spell)\n",
        "        incorrect_spellings.append(incrr_spell)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "0feaf450",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0feaf450",
        "outputId": "c7fbbb8e-e24e-4f2f-97cf-f0b9adb2de74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total number of words in Birkbeck corpus are: 36133\n"
          ]
        }
      ],
      "source": [
        "print(f'total number of words in Birkbeck corpus are: {len(incorrect_spellings)}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import wordnet as wn\n",
        "count = 0\n",
        "for _ in wn.words():\n",
        "  count += 1\n",
        "print(f'total number of words in WordNet corpus are: {count}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d54iKXkfQwHA",
        "outputId": "74a813fb-8f24-4035-d7e0-8d66566e2c13"
      },
      "id": "d54iKXkfQwHA",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total number of words in WordNet corpus are: 147306\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have **36,133** words in the corpus **BirkBeck** corpus and **147,306** words in the **WordNet** corpus.\n",
        "\n",
        "### Parallelization\n",
        "\n",
        "1. Parallelizing task across different cores of a CPU:\n",
        "\n",
        "  \n",
        "a) Running without parallelization"
      ],
      "metadata": {
        "id": "y9F7US6JGixY"
      },
      "id": "y9F7US6JGixY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1ec03a6",
      "metadata": {
        "id": "e1ec03a6",
        "outputId": "5df37f93-9733-42f8-bee9-1caade366596"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Without parallelization: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [03:31<00:00, 52.84s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "############################################################\n",
            "Without parallelization the time taken is 211.3826 second(s)\n",
            "############################################################\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "incorrect_words = ['caugt', 'nit', 'siit', 'garl']\n",
        "start = time.time()\n",
        "results = []\n",
        "for word in tqdm.tqdm(incorrect_words, desc='Without parallelization'):\n",
        "    results.append(find_closes_match(word))\n",
        "print('#' * 60)\n",
        "print(f'Without parallelization the time taken is {round(time.time()-start, 4)} second(s)')\n",
        "print('#' * 60)\n",
        "del results\n",
        "print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c658184a",
      "metadata": {
        "id": "c658184a"
      },
      "source": [
        "  b) Running with parallelization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b1f3fa8",
      "metadata": {
        "id": "2b1f3fa8",
        "outputId": "f1451a57-cb2d-4709-a7c9-65f91454f68f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "############################################################\n",
            "With parallelization the time taken is 103.3952 second(s)\n",
            "############################################################\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "results = []\n",
        "with concurrent.futures.ProcessPoolExecutor() as executor:\n",
        "    results.append(executor.map(find_closes_match, incorrect_words))\n",
        "print('#' * 60)\n",
        "print(f'With parallelization the time taken is {round(time.time() - start, 4)} second(s)')\n",
        "print('#' * 60)\n",
        "del results\n",
        "print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can clearly see that the performance (run-time) improves when we parallelize jobs across differnt cores.\n",
        "\n",
        "2. Parallelizing across different systems\n",
        "\n",
        "Fortunately enough I had multiple machines to run this analysis because the code takes a very long time to run on one machine. I parallelized it by caching the results of functions and then combing the caches folders across all the system in one system to finish the evaluation. \n",
        "\n",
        "# Analysis and result generation\n",
        "\n",
        "Running the functions and generating results."
      ],
      "metadata": {
        "id": "Bi7GkXlwDHbx"
      },
      "id": "Bi7GkXlwDHbx"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14edcd21",
      "metadata": {
        "id": "14edcd21"
      },
      "outputs": [],
      "source": [
        "results = []\n",
        "argument_list = [(icrr, crr) for icrr, crr in zip(incorrect_spellings, correct_spellings)]\n",
        "\n",
        "with concurrent.futures.ProcessPoolExecutor() as executor:\n",
        "    for result in executor.map(return_top_1_5_10_words, argument_list):\n",
        "        results.append(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "looking at a few of the results to describe the structure of the result."
      ],
      "metadata": {
        "id": "4KJjAXPYDGcx"
      },
      "id": "4KJjAXPYDGcx"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea937794",
      "metadata": {
        "id": "ea937794",
        "outputId": "c458c3dd-342f-46ea-83bc-c44f68f4c8df"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'incorrect': 'ab',\n",
              "  'correct': 'albert',\n",
              "  1: ['ab'],\n",
              "  5: ['ab',\n",
              "   'fab',\n",
              "   'a',\n",
              "   'aba',\n",
              "   'abb',\n",
              "   'abc',\n",
              "   'abm',\n",
              "   'abo',\n",
              "   'abs',\n",
              "   'alb',\n",
              "   'arb',\n",
              "   'b',\n",
              "   'cab',\n",
              "   'dab',\n",
              "   'gab',\n",
              "   'jab',\n",
              "   'lab',\n",
              "   'tab',\n",
              "   'aby',\n",
              "   'nab'],\n",
              "  10: ['ab',\n",
              "   'fab',\n",
              "   'a',\n",
              "   'aba',\n",
              "   'abb',\n",
              "   'abc',\n",
              "   'abm',\n",
              "   'abo',\n",
              "   'abs',\n",
              "   'alb',\n",
              "   'arb',\n",
              "   'b',\n",
              "   'cab',\n",
              "   'dab',\n",
              "   'gab',\n",
              "   'jab',\n",
              "   'lab',\n",
              "   'tab',\n",
              "   'aby',\n",
              "   'nab']},\n",
              " {'incorrect': 'ameraca',\n",
              "  'correct': 'america',\n",
              "  1: ['america'],\n",
              "  5: ['america',\n",
              "   'american',\n",
              "   'arauca',\n",
              "   'arca',\n",
              "   'asmera',\n",
              "   'camera',\n",
              "   'maraca',\n",
              "   'amerce'],\n",
              "  10: ['america',\n",
              "   'american',\n",
              "   'arauca',\n",
              "   'arca',\n",
              "   'asmera',\n",
              "   'camera',\n",
              "   'maraca',\n",
              "   'amerce',\n",
              "   'amber',\n",
              "   'aaa',\n",
              "   'abaca',\n",
              "   'aceraceae',\n",
              "   'aec',\n",
              "   'amberjack',\n",
              "   'ameba',\n",
              "   'ameer',\n",
              "   'americana',\n",
              "   'ametria',\n",
              "   'amora',\n",
              "   'ara',\n",
              "   'araceae',\n",
              "   'arava',\n",
              "   'arc',\n",
              "   'areca',\n",
              "   'armeria',\n",
              "   'armoracia',\n",
              "   'camera_care',\n",
              "   'cameraman',\n",
              "   'caracal',\n",
              "   'caracas',\n",
              "   'darmera',\n",
              "   'era',\n",
              "   'erica',\n",
              "   'eruca',\n",
              "   'jamaica',\n",
              "   'mac',\n",
              "   'macao',\n",
              "   'macau',\n",
              "   'macaw',\n",
              "   'maracay',\n",
              "   'marasca',\n",
              "   'mecca',\n",
              "   'mercy',\n",
              "   'mwera',\n",
              "   'namer',\n",
              "   'perca',\n",
              "   'sazerac',\n",
              "   'tamer']},\n",
              " {'incorrect': 'amercia',\n",
              "  'correct': 'america',\n",
              "  1: ['america', 'ametria', 'armeria'],\n",
              "  5: ['america',\n",
              "   'ametria',\n",
              "   'armeria',\n",
              "   'aecial',\n",
              "   'aerial',\n",
              "   'amerciable',\n",
              "   'american',\n",
              "   'amelia',\n",
              "   'amenia',\n",
              "   'amia',\n",
              "   'arca',\n",
              "   'aria',\n",
              "   'asmera',\n",
              "   'camera',\n",
              "   'mcia',\n",
              "   'merida',\n",
              "   'myrcia',\n",
              "   'amerce'],\n",
              "  10: ['america',\n",
              "   'ametria',\n",
              "   'armeria',\n",
              "   'aecial',\n",
              "   'aerial',\n",
              "   'amerciable',\n",
              "   'american',\n",
              "   'amelia',\n",
              "   'amenia',\n",
              "   'amia',\n",
              "   'arca',\n",
              "   'aria',\n",
              "   'asmera',\n",
              "   'camera',\n",
              "   'mcia',\n",
              "   'merida',\n",
              "   'myrcia',\n",
              "   'amerce']},\n",
              " {'incorrect': 'ameracan',\n",
              "  'correct': 'american',\n",
              "  1: ['american'],\n",
              "  5: ['american',\n",
              "   'america',\n",
              "   'americana',\n",
              "   'cameraman',\n",
              "   'ameban',\n",
              "   'arcane',\n",
              "   'jamaican',\n",
              "   'mean',\n",
              "   'amen',\n",
              "   'arauca',\n",
              "   'arca',\n",
              "   'arctan',\n",
              "   'asmera',\n",
              "   'barbacan',\n",
              "   'camera',\n",
              "   'maraca',\n",
              "   'merchant',\n",
              "   'merman',\n",
              "   'narcan',\n",
              "   'amerce'],\n",
              "  10: ['american',\n",
              "   'america',\n",
              "   'americana',\n",
              "   'cameraman',\n",
              "   'ameban',\n",
              "   'arcane',\n",
              "   'jamaican',\n",
              "   'mean',\n",
              "   'amen',\n",
              "   'arauca',\n",
              "   'arca',\n",
              "   'arctan',\n",
              "   'asmera',\n",
              "   'barbacan',\n",
              "   'camera',\n",
              "   'maraca',\n",
              "   'merchant',\n",
              "   'merman',\n",
              "   'narcan',\n",
              "   'amerce']},\n",
              " {'incorrect': 'apirl',\n",
              "  'correct': 'april',\n",
              "  1: ['ail', 'air', 'apr', 'april', 'sapir', 'tapir'],\n",
              "  5: ['ail', 'air', 'apr', 'april', 'sapir', 'tapir'],\n",
              "  10: ['ail',\n",
              "   'air',\n",
              "   'apr',\n",
              "   'april',\n",
              "   'sapir',\n",
              "   'tapir',\n",
              "   'airy',\n",
              "   'apical',\n",
              "   'fair',\n",
              "   'il',\n",
              "   'spiral',\n",
              "   'airily',\n",
              "   'fairly',\n",
              "   'afrl',\n",
              "   'ai',\n",
              "   'aire',\n",
              "   'airs',\n",
              "   'al',\n",
              "   'alir',\n",
              "   'amir',\n",
              "   'anil',\n",
              "   'apar',\n",
              "   'aper',\n",
              "   'apia',\n",
              "   'apiary',\n",
              "   'apis',\n",
              "   'ar',\n",
              "   'aril',\n",
              "   'axil',\n",
              "   'bail',\n",
              "   'dail',\n",
              "   'diapir',\n",
              "   'earl',\n",
              "   'girl',\n",
              "   'hail',\n",
              "   'hair',\n",
              "   'ir',\n",
              "   'jail',\n",
              "   'kail',\n",
              "   'lair',\n",
              "   'mail',\n",
              "   'marl',\n",
              "   'nail',\n",
              "   'napier',\n",
              "   'pail',\n",
              "   'pair',\n",
              "   'pi',\n",
              "   'pier',\n",
              "   'pile',\n",
              "   'pill',\n",
              "   'pr',\n",
              "   'purl',\n",
              "   'rail',\n",
              "   'rapier',\n",
              "   'sail',\n",
              "   'tail',\n",
              "   'wail',\n",
              "   'airt',\n",
              "   'aspire',\n",
              "   'birl',\n",
              "   'fail']}]"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results[50:55]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50e7344f",
      "metadata": {
        "id": "50e7344f"
      },
      "outputs": [],
      "source": [
        "del argument_list"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation\n",
        "\n",
        "We have a custom function to find success at k for the words using the list of dictionaries that we generated in the step above. We used this to cross validate the results generated using `pytrec_eval` and the results match. "
      ],
      "metadata": {
        "id": "EM6koKKzDgoI"
      },
      "id": "EM6koKKzDgoI"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "204dbc88",
      "metadata": {
        "id": "204dbc88",
        "outputId": "fa9cbee4-ae24-45b8-ef25-282622701609"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            " \"ab\": {\n",
            "  \"success_1\": 0.0,\n",
            "  \"success_5\": 0.0,\n",
            "  \"success_10\": 0.0\n",
            " },\n",
            " \"ameraca\": {\n",
            "  \"success_1\": 1.0,\n",
            "  \"success_5\": 1.0,\n",
            "  \"success_10\": 1.0\n",
            " },\n",
            " \"amercia\": {\n",
            "  \"success_1\": 0.0,\n",
            "  \"success_5\": 1.0,\n",
            "  \"success_10\": 1.0\n",
            " },\n",
            " \"ameracan\": {\n",
            "  \"success_1\": 1.0,\n",
            "  \"success_5\": 1.0,\n",
            "  \"success_10\": 1.0\n",
            " },\n",
            " \"apirl\": {\n",
            "  \"success_1\": 0.0,\n",
            "  \"success_5\": 1.0,\n",
            "  \"success_10\": 1.0\n",
            " }\n",
            "}\n",
            "success_1 average: 0.26672162034856334\n",
            "success_10 average: 0.47850918511540275\n",
            "success_5 average: 0.41371290626471974\n"
          ]
        }
      ],
      "source": [
        "success_at_k = return_success_at_k(results)\n",
        "\n",
        "query = {}\n",
        "results_eval = {}\n",
        "for result in results:\n",
        "    query[result[\"incorrect\"]] = {result[\"correct\"]: 1}\n",
        "    results_eval[result[\"incorrect\"]] = {}\n",
        "    for word in result[1]:\n",
        "        results_eval[result[\"incorrect\"]][word] = 1\n",
        "\n",
        "    for word in result[5]:\n",
        "        if word not in results_eval[result[\"incorrect\"]].keys():\n",
        "            results_eval[result[\"incorrect\"]][word] = 1/5\n",
        "\n",
        "    for word in result[10]:\n",
        "        if word not in results_eval[result[\"incorrect\"]].keys():\n",
        "            results_eval[result[\"incorrect\"]][word] = 1/10\n",
        "\n",
        "evaluator = pytrec_eval.RelevanceEvaluator(query, {'success'})\n",
        "\n",
        "print(json.dumps(evaluator.evaluate(results_eval[50:55]), indent=1))\n",
        "eval = evaluator.evaluate(results_eval)\n",
        "\n",
        "for measure in sorted(list(eval[list(eval.keys())[0]].keys())):\n",
        "    print(measure, 'average:',\n",
        "          pytrec_eval.compute_aggregated_measure(\n",
        "              measure, [query_measures[measure] for query_measures in eval.values()])\n",
        "          )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf3c6240",
      "metadata": {
        "id": "bf3c6240"
      },
      "outputs": [],
      "source": [
        "# END"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "assignment1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
